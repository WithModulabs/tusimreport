#!/usr/bin/env python3
"""
Enhanced Korean Sentiment Analysis Agent
Naver News API + Tavily Search API ë“€ì–¼ ì†ŒìŠ¤ ê¸°ë°˜

Dr. Alex Rivera (Tavily CTO) ê¸°ìˆ  ì§€ì›ìœ¼ë¡œ í–¥ìƒëœ ê°ì • ë¶„ì„:
- Naver News API: í•œêµ­ ë¡œì»¬ ë‰´ìŠ¤ (50ê°œ)
- Tavily Search API: ê¸€ë¡œë²Œ ë‰´ìŠ¤ + AI í•„í„°ë§ (10ê°œ)
- ë“€ì–¼ ì†ŒìŠ¤ í†µí•©ìœ¼ë¡œ í¸í–¥ì„± ê°ì†Œ ë° ì»¤ë²„ë¦¬ì§€ í™•ì¥
- LLM ê¸°ë°˜ ì¢…í•© ê°ì„± ë¶„ì„ ë° í† í”½ ì¶”ì¶œ
"""

import logging
import requests
import os
from typing import Dict, Any, List
from datetime import datetime, timedelta

from langchain_core.tools import tool
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage

from config.settings import get_llm_model, settings
from data.tavily_api_client import TavilyNewsClient

logger = logging.getLogger(__name__)


@tool
def get_enhanced_news_sentiment(company_name: str, stock_code: str) -> Dict[str, Any]:
    """
    í–¥ìƒëœ ë“€ì–¼ ì†ŒìŠ¤ ë‰´ìŠ¤ ê°ì • ë¶„ì„
    Naver News API + Tavily Search API í†µí•© (Dr. Rivera ê¸°ìˆ ì§€ì›)
    """
    try:
        logger.info(f"Enhanced dual-source news sentiment analysis for {company_name} ({stock_code})")

        # 1. Naver News API ë°ì´í„° ìˆ˜ì§‘
        naver_data = _fetch_naver_news(company_name)

        # 2. Tavily Search API ë°ì´í„° ìˆ˜ì§‘
        tavily_data = _fetch_tavily_news(company_name)

        # 3. ë“€ì–¼ ì†ŒìŠ¤ í†µí•© ë° LLM ë¶„ì„
        return _analyze_dual_source_sentiment(company_name, stock_code, naver_data, tavily_data)


    except Exception as e:
        logger.error(f"Error in enhanced dual-source news sentiment analysis: {str(e)}")
        return {"error": str(e)}


def _fetch_naver_news(company_name: str) -> Dict[str, Any]:
    """ë„¤ì´ë²„ ë‰´ìŠ¤ API ë°ì´í„° ìˆ˜ì§‘"""
    try:
        client_id = settings.naver_client_id
        client_secret = settings.naver_client_secret

        if not client_id or not client_secret:
            return {"error": "Naver API ìê²© ì¦ëª…ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", "items": []}

        # ìµœì í™”ëœ ê²€ìƒ‰ì–´ ìƒì„±
        if company_name == "KT":
            search_query = f"{company_name} ì£¼ì‹"
        elif company_name in ["LG", "SK"]:
            search_query = f"{company_name} ê·¸ë£¹"
        elif company_name in ["í˜„ëŒ€ì°¨"]:
            search_query = f"{company_name} ìë™ì°¨"
        else:
            search_query = f"{company_name} ì£¼ì‹"

        url = "https://openapi.naver.com/v1/search/news.json"
        headers = {
            "X-Naver-Client-Id": client_id,
            "X-Naver-Client-Secret": client_secret,
        }
        params = {
            "query": search_query,
            "display": 10,  # 3ì ì „ë¬¸ê°€ ì¶”ì²œ: 10ê°œë¡œ í†µì¼
            "sort": "sim",
        }

        response = requests.get(url, headers=headers, params=params, timeout=10)
        response.raise_for_status()
        return response.json()

    except Exception as e:
        logger.error(f"Naver News API ì˜¤ë¥˜: {str(e)}")
        return {"error": str(e), "items": []}


def _fetch_tavily_news(company_name: str) -> Dict[str, Any]:
    """Tavily Search API ë°ì´í„° ìˆ˜ì§‘ (íˆ¬ì ì „ë¬¸ê°€ ìµœì í™”)"""
    try:
        tavily_client = TavilyNewsClient(settings.tavily_api_key)
        return tavily_client.search_company_news(
            company_name=company_name,
            max_results=10  # 3ì ì „ë¬¸ê°€ ì¶”ì²œ: 10ê°œë¡œ í†µì¼
        )
    except Exception as e:
        logger.error(f"Tavily Search API ì˜¤ë¥˜: {str(e)}")
        return {"error": str(e), "news_items": []}


def _analyze_dual_source_sentiment(company_name: str, stock_code: str, naver_data: Dict, tavily_data: Dict) -> Dict[str, Any]:
    """ë“€ì–¼ ì†ŒìŠ¤ í†µí•© ê°ì • ë¶„ì„ (Dr. Rivera ìµœì í™”)"""
    try:
        # LLM ì´ˆê¸°í™”
        llm_provider, llm_model_name, llm_api_key = get_llm_model()
        if llm_provider == "gemini":
            sentiment_llm = ChatGoogleGenerativeAI(
                model=llm_model_name, temperature=0.0, google_api_key=llm_api_key
            )
        else:
            sentiment_llm = ChatOpenAI(
                model=llm_model_name, temperature=0.0, api_key=llm_api_key
            )

        # 3ì ì „ë¬¸ê°€ ì¶”ì²œ: ê· í˜•ì¡íŒ ë¶„ì„ ë°ì´í„° (ê° 10ê°œì”©)
        naver_texts = []
        if naver_data.get("items"):
            naver_texts = [
                f"[Naver] {item['title']} - {item['description']}"
                for item in naver_data["items"]  # 10ê°œ ì „ì²´
            ]

        # Tavily ë‰´ìŠ¤ í…ìŠ¤íŠ¸ ì¤€ë¹„
        tavily_texts = []
        if tavily_data.get("news_items"):
            tavily_texts = [
                f"[Tavily] {item['title']} - {item['content'][:200]}"
                for item in tavily_data["news_items"]  # 10ê°œ ì „ì²´
            ]

        # í†µí•© ë‰´ìŠ¤ í…ìŠ¤íŠ¸
        all_news_texts = naver_texts + tavily_texts

        if not all_news_texts:
            return {"error": "ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}

        # Dr. Rivera ì¶”ì²œ í”„ë¡¬í”„íŠ¸ (ë“€ì–¼ ì†ŒìŠ¤ ìµœì í™”)
        analysis_prompt = f"""
ë‹¤ìŒì€ {company_name} ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ë„¤ì´ë²„(í•œêµ­) + Tavily(ê¸€ë¡œë²Œ) ë“€ì–¼ ì†ŒìŠ¤ì—ì„œ ìˆ˜ì§‘í•œ ë°ì´í„°ì…ë‹ˆë‹¤.
ê° ë‰´ìŠ¤ ì•ì˜ [Naver] ë˜ëŠ” [Tavily] íƒœê·¸ë¡œ ì¶œì²˜ë¥¼ êµ¬ë¶„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

[ë‰´ìŠ¤ ë°ì´í„°]
{chr(10).join(all_news_texts)}

[ë¶„ì„ ìš”êµ¬ì‚¬í•­]
1. ì „ì²´ì ì¸ ê°ì„±ì„ 'ë§¤ìš° ê¸ì •', 'ê¸ì •', 'ì¤‘ë¦½', 'ë¶€ì •', 'ë§¤ìš° ë¶€ì •' ì¤‘ í•˜ë‚˜ë¡œ í‰ê°€
2. ê°ì„± ì ìˆ˜ë¥¼ -1.0 (ë§¤ìš° ë¶€ì •) ~ 1.0 (ë§¤ìš° ê¸ì •) ì‚¬ì´ ìˆ˜ì¹˜ë¡œ ê³„ì‚°
3. í•µì‹¬ í† í”½ 3ê°€ì§€ë¥¼ í‚¤ì›Œë“œë¡œ ìš”ì•½
4. ê°€ì¥ ê¸ì •ì /ë¶€ì •ì  í—¤ë“œë¼ì¸ ê° 1ê°œì”© ì„ ì •
5. ë°ì´í„° ì†ŒìŠ¤ë³„ í¸í–¥ì„± ê³ ë ¤ (í•œêµ­ vs ê¸€ë¡œë²Œ ì‹œê°)

[ì¶œë ¥ í˜•ì‹]
- Overall Sentiment: [í‰ê°€ ê²°ê³¼]
- Sentiment Score: [ì ìˆ˜]
- Key Topics: [í† í”½1, í† í”½2, í† í”½3]
- Most Positive Headline: [í—¤ë“œë¼ì¸]
- Most Negative Headline: [í—¤ë“œë¼ì¸]
- Source Balance: [ë„¤ì´ë²„ì™€ Tavily ë°ì´í„° ê· í˜•ì„± í‰ê°€]
"""

        # LLM ë¶„ì„ ì‹¤í–‰
        llm_response = sentiment_llm.invoke(analysis_prompt)

        # ì‘ë‹µ íŒŒì‹±
        lines = llm_response.content.strip().split("\n")
        parsed_result = {}
        for line in lines:
            if ":" in line:
                key, value = line.split(":", 1)
                parsed_result[key.strip()] = value.strip()

        # 3ì ì „ë¬¸ê°€ ì¶”ì²œ: ì™„ì „í•œ ë‰´ìŠ¤ ì†ŒìŠ¤ íˆ¬ëª…ì„± (ì´ 20ê°œ)
        news_sources = []

        # ë„¤ì´ë²„ ë‰´ìŠ¤ ì†ŒìŠ¤ (10ê°œ - ì™„ì „ ê³µê°œ)
        if naver_data.get("items"):
            for item in naver_data["items"]:
                news_sources.append({
                    "title": item.get("title", "").replace("<b>", "").replace("</b>", ""),
                    "url": item.get("link", ""),
                    "source": "[Naver] ë„¤ì´ë²„ ë‰´ìŠ¤ API",
                    "pub_date": item.get("pubDate", ""),
                    "type": "naver"
                })

        # Tavily ë‰´ìŠ¤ ì†ŒìŠ¤ (10ê°œ - ì™„ì „ ê³µê°œ)
        if tavily_data.get("news_items"):
            for item in tavily_data["news_items"]:
                # Dr. Rivera ì¶”ì²œ: ìƒì„¸í•œ ì¶œì²˜ ì •ë³´
                source_domain = item.get('source', 'Unknown')
                news_sources.append({
                    "title": item.get("title", ""),
                    "url": item.get("url", ""),
                    "source": f"[Tavily] {source_domain}",
                    "score": item.get("score", 0),
                    "type": "tavily"
                })

        return {
            "status": "success",
            "company_name": company_name,
            "stock_code": stock_code,
            "data_sources": {
                "naver_news_count": len(naver_data.get("items", [])),
                "tavily_news_count": len(tavily_data.get("news_items", [])),
                "total_analyzed": len(all_news_texts)
            },
            "sentiment_analysis": parsed_result,
            "news_sources": news_sources,
            "tavily_ai_summary": tavily_data.get("ai_summary", ""),
            "data_source": "Enhanced Dual-Source: Naver News API + Tavily Search API",
            "last_updated": datetime.now().isoformat(),
        }

    except Exception as e:
        logger.error(f"ë“€ì–¼ ì†ŒìŠ¤ ê°ì • ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        return {"error": str(e)}


# ë„êµ¬ ëª©ë¡ - í–¥ìƒëœ ë“€ì–¼ ì†ŒìŠ¤ ë²„ì „
sentiment_tools = [get_enhanced_news_sentiment]

# ê¸°ì¡´ í•¨ìˆ˜ëª…ê³¼ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
get_naver_news_sentiment = get_enhanced_news_sentiment


def create_sentiment_agent():
    """Sentiment Analysis Agent ìƒì„± í•¨ìˆ˜"""
    llm_provider, llm_model_name, llm_api_key = get_llm_model()
    if llm_provider == "gemini":
        llm = ChatGoogleGenerativeAI(
            model=llm_model_name, temperature=0.1, google_api_key=llm_api_key
        )
    else:
        llm = ChatOpenAI(model=llm_model_name, temperature=0.1, api_key=llm_api_key)

    prompt = (
        "ë‹¹ì‹ ì€ ë‰´ìŠ¤ì™€ ì‹œì¥ ì‹¬ë¦¬ë¥¼ ë¶„ì„í•˜ëŠ” ê°ì • ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. "
        "ì¼ë°˜ íˆ¬ììë“¤ì´ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í˜„ì¬ ì‹œì¥ì˜ ë¶„ìœ„ê¸°ì™€ ì—¬ë¡ ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.\n\n"

        "ë¨¼ì € `get_naver_news_sentiment` ë„êµ¬ë¥¼ ì‚¬ìš©í•´ì„œ ìµœì‹  ë‰´ìŠ¤ ê°ì • ë¶„ì„ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•œ í›„, "
        "ë‹¤ìŒê³¼ ê°™ì´ ì¹œê·¼í•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”:\n\n"

        "1. í˜„ì¬ ì´ ì¢…ëª©ì— ëŒ€í•œ ë‰´ìŠ¤ ë¶„ìœ„ê¸°ê°€ ì–´ë–¤ì§€ ê°„ë‹¨íˆ ìš”ì•½í•´ì£¼ì„¸ìš”\n"
        "   - ì „ì²´ì ìœ¼ë¡œ ê¸ì •ì ì¸ì§€, ë¶€ì •ì ì¸ì§€, ì¤‘ë¦½ì ì¸ì§€\n"
        "   - ê°ì • ì ìˆ˜ë¥¼ ì‰¬ìš´ ë§ë¡œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n\n"

        "2. ì–´ë–¤ ì¢…ë¥˜ì˜ ë‰´ìŠ¤ê°€ ë§ì€ì§€ ì•Œë ¤ì£¼ì„¸ìš”\n"
        "   - ê°€ì¥ ê¸ì •ì ì¸ ë‰´ìŠ¤ëŠ” ì–´ë–¤ ë‚´ìš©ì¸ì§€\n"
        "   - ê°€ì¥ ìš°ë ¤ë˜ëŠ” ë‰´ìŠ¤ëŠ” ì–´ë–¤ ë‚´ìš©ì¸ì§€\n"
        "   - ì£¼ìš” í‚¤ì›Œë“œë“¤ì„ ì•Œê¸° ì‰½ê²Œ ì„¤ëª…í•´ì£¼ì„¸ìš”\n\n"

        "3. íˆ¬ìì ì…ì¥ì—ì„œ ì´ëŸ° ë‰´ìŠ¤ë“¤ì´ ì–´ë–¤ ì˜ë¯¸ì¸ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”\n"
        "   - ì‹œì¥ ì°¸ì—¬ìë“¤ì´ ì–´ë–¤ ë§ˆìŒê°€ì§ì„ ê°€ì§€ê³  ìˆì„ ê²ƒ ê°™ì€ì§€\n"
        "   - ë‹¨ê¸°ì ìœ¼ë¡œ ì£¼ê°€ì— ì–´ë–¤ ì˜í–¥ì„ ì¤„ ìˆ˜ ìˆëŠ”ì§€\n"
        "   - ì´ëŸ° ë¶„ìœ„ê¸°ê°€ ì–¸ì œê¹Œì§€ ì´ì–´ì§ˆ ê²ƒ ê°™ì€ì§€\n\n"

        "4. íˆ¬ììë“¤ì´ ì£¼ì˜í•´ì„œ ë´ì•¼ í•  ì ë“¤ì„ ì¡°ì–¸í•´ì£¼ì„¸ìš”\n"
        "   - ë‰´ìŠ¤ì˜ ì‹ ë¢°ì„±ì€ ì–´ë–¤ì§€\n"
        "   - ê°ì •ì ìœ¼ë¡œ ê³¼ë„í•˜ê²Œ ë°˜ì‘í•˜ì§€ ì•Šìœ¼ë ¤ë©´ ì–´ë–»ê²Œ í•´ì•¼ í•˜ëŠ”ì§€\n\n"

        "5. ğŸ“° ë¶„ì„ì— ì‚¬ìš©ëœ ë‰´ìŠ¤ ì¶œì²˜ë¥¼ íˆ¬ëª…í•˜ê²Œ ê³µê°œí•´ì£¼ì„¸ìš”\n"
        "   - ìƒìœ„ 5-10ê°œ ë‰´ìŠ¤ì˜ ì œëª©ê³¼ ë°œí–‰ì¼ì„ ê°„ë‹¨íˆ ë‚˜ì—´í•´ì£¼ì„¸ìš”\n"
        "   - ì–´ë–¤ ì–¸ë¡ ì‚¬ì˜ ë‰´ìŠ¤ê°€ ì£¼ë¡œ ì‚¬ìš©ë˜ì—ˆëŠ”ì§€ ì•Œë ¤ì£¼ì„¸ìš”\n\n"

        "ì „ë¬¸ ìš©ì–´ë³´ë‹¤ëŠ” ì‰¬ìš´ ë§ë¡œ ì„¤ëª…í•´ì£¼ì‹œê³ , ìˆ«ìë‚˜ ì ìˆ˜ë¥¼ ì œì‹œí•  ë•ŒëŠ” "
        "ê·¸ê²ƒì´ ì‹¤ì œë¡œ ì–´ë–¤ ì˜ë¯¸ì¸ì§€ êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ì„¤ëª…í•´ì£¼ì„¸ìš”. "
        "ë§ˆì¹˜ ì¹œêµ¬ê°€ íˆ¬ì ì¡°ì–¸ì„ í•´ì£¼ë“¯ì´ ìì—°ìŠ¤ëŸ½ê³  ë”°ëœ»í•œ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n\n"

        "ì°¸ê³ : ì´ ë¶„ì„ì€ ë‰´ìŠ¤ ì—¬ë¡  ì°¸ê³ ìë£Œì´ë©° íˆ¬ì ì¶”ì²œì´ ì•„ë‹™ë‹ˆë‹¤. ê°ê´€ì ì¸ ì •ë³´ ì œê³µì„ ëª©ì ìœ¼ë¡œ í•©ë‹ˆë‹¤.\n\n"
        "ğŸš¨ ì¤‘ìš”: ë¶„ì„ì„ ëª¨ë‘ ë§ˆì¹œ í›„ ë°˜ë“œì‹œ ë§ˆì§€ë§‰ ì¤„ì— 'SENTIMENT_ANALYSIS_COMPLETE'ë¼ê³  ì •í™•íˆ ì ì–´ì£¼ì„¸ìš”. ì´ê²ƒì€ ì‹œìŠ¤í…œì´ ë¶„ì„ ì™„ë£Œë¥¼ í™•ì¸í•˜ëŠ” ë° í•„ìˆ˜ì…ë‹ˆë‹¤."
    )

    return create_react_agent(model=llm, tools=sentiment_tools, prompt=prompt, name="sentiment_expert")


# ì´ íŒŒì¼ì´ ì§ì ‘ ì‹¤í–‰ë  ë•Œ í…ŒìŠ¤íŠ¸ìš©
if __name__ == "__main__":
    from dotenv import load_dotenv

    load_dotenv()

    company_name = "ì‚¼ì„±ì „ì"
    stock_code = "005930"

    print(f"--- Testing Sentiment Analysis for {company_name} ---")
    result = get_naver_news_sentiment(company_name, stock_code)

    import json

    print(json.dumps(result, indent=2, ensure_ascii=False))
